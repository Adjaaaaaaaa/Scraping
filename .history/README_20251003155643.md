# Book Scraper & API

Projet réalisé dans le cadre de la formation **Développeur IA chez Simplon**.  
Ce projet scrape des livres depuis [Books to Scrape](http://books.toscrape.com/) et expose les données via une **API RESTful FastAPI**.  
Il inclut également la gestion de l’historique des modifications des livres.

---

## 1. Structure du projet

```
books_scraper/
├─ books_api/                        
│  ├─ __init__.py
│  ├─ main.py                        # Point d’entrée FastAPI
│  ├─ presentation/
│  │  ├─ __init__.py
│  │  ├─ routes.py                   # Routes de l’API
│  │  └─ schemas.py                  # Pydantic schemas pour validation
│  ├─ data/
│  │  ├─ __init__.py
│  │  ├─ database.py                 # Connexion DB et session
│  │  ├─ tables.py                   # Mapping SQLAlchemy vers table books
│  │  └─ repositories.py             # Logique de lecture/filtrage des livres
│  └─ domain/
│     └─ models.py                   # Classe Book (optionnelle)
├─ books_scraper/                     
│  ├─ __init__.py
│  ├─ items.py                        # Items Scrapy
│  ├─ models.py                       # Définition Book et BookHistory (SQLAlchemy)
│  ├─ pipelines.py                    # Nettoyage & sauvegarde dans DB
│  ├─ settings.py                     # Paramètres Scrapy
│  └─ spiders/
│     └─ books.py                     # Spider principal
├─ books.db                            # Base SQLite générée par le scraper
├─ run_daily.py                        # Scheduler pour exécution automatique du spider
├─ requirements.txt
└─ README.md
```

---

## 2. Dépendances

- Python >= 3.10 recommandé
- Librairies :

```text
fastapi
uvicorn[standard]
sqlalchemy
pydantic
scrapy
schedule
```

## 3. Installation

### 1. Créer et activer l’environnement virtuel :

#### Windows (PowerShell)
```bash
python -m venv venv
.env\Scripts\Activate.ps1
```
#### macOS / Linux
```bash
python3 -m venv venv
source venv/bin/activate
```
### 2. Installer les dépendances 
```bash
pip install -r requirements.txt
```
---

## 4. Base de données

**SQLite** par défaut : `books.db`  

### Tables principales

**`books`** : informations sur les livres  

| Champ             | Type      |
|------------------|-----------|
| id               | Integer   |
| title            | String    |
| category         | String    |
| price            | Float     |
| availability     | String    |
| rating           | Integer   |
| url              | String    |
| copies_available | Integer   |
| upc              | String    |
| price_excl_tax   | Float     |
| price_incl_tax   | Float     |
| tax              | Float     |
| num_reviews      | Integer   |

**`book_history`** : historique des modifications  

| Champ        | Type      |
|-------------|-----------|
| id          | Integer   |
| book_upc    | String    |
| action      | String    | # added / updated / deleted
| old_data    | JSON      |
| new_data    | JSON      |
| change_date | DateTime  |

---

## 5. Scraping

### a) Lancer le spider manuellement

```bash
scrapy crawl books
```

- Scrape les livres depuis [Books to Scrape](http://books.toscrape.com/)  
- Nettoyage via `CleanBooksPipeline`  
- Sauvegarde et historique via `SaveBooksPipeline`

### b) Exécution automatique quotidienne

```bash
python run_daily.py
```

- Exécute le spider tous les jours à 02h00  
- Enregistre les changements dans `book_history`

---

## 6. API FastAPI

### a) Lancer le serveur

```bash
uvicorn books_api.main:app --reload
```

- Swagger UI : [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)  
- ReDoc : [http://127.0.0.1:8000/redoc](http://127.0.0.1:8000/redoc)

### b) Endpoints principaux

| Endpoint                             | Méthode | Description |
|--------------------------------------|---------|------------|
| `/books`                              | GET     | Liste tous les livres avec pagination (`skip`, `limit`) |
| `/books/upc/{upc}`                    | GET     | Récupère un livre par son UPC |
| `/books/price`                        | GET     | Filtre par prix (`min_price`, `max_price`) |
| `/books/category/{category}`          | GET     | Filtre par catégorie |
| `/books/availability/{availability}`  | GET     | Filtre par disponibilité (`In stock` / `Out of stock`) |
| `/books/search`                       | GET     | Recherche combinée : `category`, `min_price`, `max_price`, `availability`, `rating`, `skip`, `limit` |

---

### c) Exemple `/books/search`

```http
GET /books/search?category=Fiction&min_price=10&max_price=50&availability=In%20stock&rating=5&skip=0&limit=10
```

- Renvoie jusqu’à 10 livres de catégorie "Fiction", en stock, prix entre 10 et 50, et rating = 5

---

## 7. Interface API

L’API est documentée automatiquement grâce à **FastAPI**.  

### Swagger UI
Accessible via : [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

![Swagger UI](images/swagger_ui.png)

### ReDoc
Accessible via : [http://127.0.0.1:8000/redoc](http://127.0.0.1:8000/redoc)

![ReDoc](images/redoc.png)

---

## 8. Bonnes pratiques

1. Toujours lancer le scraper **avant d’interroger l’API** pour avoir des données fraîches  
2. Utiliser `/books/search` pour combiner plusieurs filtres  
3. Pour filtrer par UPC, utiliser `/books/upc/{upc}`  
4. Vérifier la base avec SQLite si l’API retourne une liste vide  
